{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15628a15",
   "metadata": {
    "id": "15628a15"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a5bcd6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "16a5bcd6",
    "outputId": "ad19d06a-cd6a-4cb2-9f41-19fb69785548"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "df=pd.read_csv(\"data_spam.csv\",encoding='latin-1')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qCXx63AbD8OM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCXx63AbD8OM",
    "outputId": "01ad6fa8-09c5-4b5b-d882-060793d4d3d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3ef7a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "2e3ef7a7",
    "outputId": "afb9e483-fa76-4c30-b4c3-90d9eec6eac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop cols\n",
    "df.drop('Unnamed: 2',axis=1, inplace=True)\n",
    "df.drop('Unnamed: 3',axis=1, inplace=True)\n",
    "df.drop('Unnamed: 4',axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "VxVMpxF9EPiZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxVMpxF9EPiZ",
    "outputId": "6d19ba89-ad0e-473e-db1c-33ab961e7172"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1    0\n",
       "v2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "T63kmcmpEX97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T63kmcmpEX97",
    "outputId": "9486c394-ae70-445d-dd58-62de8200c35f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vhPQgKX1FT_R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhPQgKX1FT_R",
    "outputId": "022e62e3-115a-4641-86fc-bf6fbab272f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d68cee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "44d68cee",
    "outputId": "9b288f89-41b0-4316-f9ed-b67eb0d29dec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  go until jurong point, crazy.. available only ...\n",
       "1   ham                      ok lar... joking wif u oni...\n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3   ham  u dun say so early hor... u c already then say...\n",
       "4   ham  nah i don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert text to lower case\n",
    "df['v2'] = df['v2'].str.lower()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44814628",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44814628",
    "outputId": "b573d41c-87ec-4b56-8685-3e1323a86cf1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ahmed\n",
      "[nltk_data]     Ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a211ba8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a211ba8",
    "outputId": "db00df7f-a1d6-493d-f538-5b1ba9fe72da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d8c031",
   "metadata": {
    "id": "12d8c031"
   },
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "def remove_stopwords(x):\n",
    "    return \" \".join([word for word in str(x).split() if word not in stopwords])\n",
    "df['v2']= df['v2'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63fffd55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "63fffd55",
    "outputId": "427371fb-e53a-4f48-e3f2-3f37134adeeb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point, crazy.. available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor... u c already say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goes usf, lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  go jurong point, crazy.. available bugis n gre...\n",
       "1   ham                      ok lar... joking wif u oni...\n",
       "2  spam  free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3   ham          u dun say early hor... u c already say...\n",
       "4   ham            nah think goes usf, lives around though"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23095100",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "23095100",
    "outputId": "150da97f-d88e-4a48-a5fc-a695bf10b9b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, , crazy, , , available, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, , , , joking, wif, u, oni, , , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, early, hor, , , , u, c, already,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goes, usf, , lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  [go, jurong, point, , crazy, , , available, bu...\n",
       "1   ham         [ok, lar, , , , joking, wif, u, oni, , , ]\n",
       "2  spam  [free, entry, 2, wkly, comp, win, fa, cup, fin...\n",
       "3   ham  [u, dun, say, early, hor, , , , u, c, already,...\n",
       "4   ham   [nah, think, goes, usf, , lives, around, though]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply tokenization\n",
    "import re # regular text\n",
    "def tokenize(text):\n",
    "  # ignore non alpha\n",
    "  tokens = re.split('\\W', text)\n",
    "  return tokens\n",
    "df[\"v2\"] = df[\"v2\"].apply( lambda x:tokenize(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bbd6dad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4bbd6dad",
    "outputId": "4a973874-ba46-49df-a334-7835272b5baa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, , crazi, , , avail, bugi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, , , , joke, wif, u, oni, , , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor, , , , u, c, alreadi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goe, usf, , live, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  [go, jurong, point, , crazi, , , avail, bugi, ...\n",
       "1   ham           [ok, lar, , , , joke, wif, u, oni, , , ]\n",
       "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...\n",
       "3   ham  [u, dun, say, earli, hor, , , , u, c, alreadi,...\n",
       "4   ham     [nah, think, goe, usf, , live, around, though]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply stemming\n",
    "ps = nltk.PorterStemmer()\n",
    "def stemming(text):\n",
    "  Stext=[ps.stem(i) for i in text]\n",
    "  return Stext\n",
    "df[\"v2\"]=df[\"v2\"].apply(lambda x: stemming(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f9a0c8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f9a0c8e",
    "outputId": "b74aaf34-718c-48c8-f510-a6370a48e0bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Ahmed\n",
      "[nltk_data]     Ali\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d8f7a8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "0d8f7a8f",
    "outputId": "f4c608a1-36ba-435a-98d5-2fef6b98a466"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ahmed\n",
      "[nltk_data]     Ali\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, , crazi, , , avail, bugi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, , , , joke, wif, u, oni, , , ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor, , , , u, c, alreadi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goe, usf, , live, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  [go, jurong, point, , crazi, , , avail, bugi, ...\n",
       "1   ham           [ok, lar, , , , joke, wif, u, oni, , , ]\n",
       "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...\n",
       "3   ham  [u, dun, say, earli, hor, , , , u, c, alreadi,...\n",
       "4   ham     [nah, think, goe, usf, , live, around, though]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply lemmatization\n",
    "nltk.download('wordnet')\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "def lemmatiztion(tokentext):\n",
    "  text=[wn.lemmatize(word) for word in tokentext]\n",
    "  return text\n",
    "\n",
    "df[\"v2\"] =df[\"v2\"].apply(lambda x : lemmatiztion(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69b1b859",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "69b1b859",
    "outputId": "48ccca33-577b-4882-d77b-a0d882d0fe4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>msg_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, , crazi, , , avail, bugi, ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, , , , joke, wif, u, oni, , , ]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor, , , , u, c, alreadi,...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goe, usf, , live, around, though]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  msg_length\n",
       "0   ham  [go, jurong, point, , crazi, , , avail, bugi, ...          25\n",
       "1   ham           [ok, lar, , , , joke, wif, u, oni, , , ]          12\n",
       "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...          29\n",
       "3   ham  [u, dun, say, earli, hor, , , , u, c, alreadi,...          15\n",
       "4   ham     [nah, think, goe, usf, , live, around, though]           8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature generation length of message \n",
    "df[\"msg_length\"]=df[\"v2\"].apply(lambda x: len(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59cde305",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "59cde305",
    "outputId": "eda7ac47-a8e0-4d10-bf4b-c01f1b67e96f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>msg_length</th>\n",
       "      <th>punc_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, , crazi, , , avail, bugi, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, , , , joke, wif, u, oni, , , ]</td>\n",
       "      <td>12</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>29</td>\n",
       "      <td>3.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor, , , , u, c, alreadi,...</td>\n",
       "      <td>15</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goe, usf, , live, around, though]</td>\n",
       "      <td>8</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  msg_length  \\\n",
       "0   ham  [go, jurong, point, , crazi, , , avail, bugi, ...          25   \n",
       "1   ham           [ok, lar, , , , joke, wif, u, oni, , , ]          12   \n",
       "2  spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...          29   \n",
       "3   ham  [u, dun, say, earli, hor, , , , u, c, alreadi,...          15   \n",
       "4   ham     [nah, think, goe, usf, , live, around, though]           8   \n",
       "\n",
       "   punc_percentage  \n",
       "0        36.000000  \n",
       "1        50.000000  \n",
       "2         3.448276  \n",
       "3        40.000000  \n",
       "4        12.500000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature generation using precentage of puncutaions \n",
    "import string\n",
    "def punctuation_count(text):\n",
    "  count=sum([1 for c in text if c in string.punctuation])\n",
    "  return 100*count/len(text)\n",
    "\n",
    "df[\"punc_percentage\"]=df[\"v2\"].apply(lambda x: punctuation_count(x))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb8cd8cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb8cd8cd",
    "outputId": "ec99fe58-ed25-4723-bc2f-1635108ad5b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        v1                                                 v2  msg_length  \\\n",
      "0      ham  [go, jurong, point, , crazi, , , avail, bugi, ...        25.0   \n",
      "1      ham           [ok, lar, , , , joke, wif, u, oni, , , ]        12.0   \n",
      "2     spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...        29.0   \n",
      "3      ham  [u, dun, say, earli, hor, , , , u, c, alreadi,...        15.0   \n",
      "4      ham     [nah, think, goe, usf, , live, around, though]         8.0   \n",
      "...    ...                                                ...         ...   \n",
      "5105   NaN                                                NaN         NaN   \n",
      "5108   NaN                                                NaN         NaN   \n",
      "5129   NaN                                                NaN         NaN   \n",
      "5141   NaN                                                NaN         NaN   \n",
      "5164   NaN                                                NaN         NaN   \n",
      "\n",
      "      punc_percentage   00  000  000pe  008704050406  0089  0121  ...   ó_  \\\n",
      "0           36.000000  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "1           50.000000  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "2            3.448276  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "3           40.000000  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "4           12.500000  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "...               ...  ...  ...    ...           ...   ...   ...  ...  ...   \n",
      "5105              NaN  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "5108              NaN  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "5129              NaN  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "5141              NaN  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "5164              NaN  0.0  0.0    0.0           0.0   0.0   0.0  ...  0.0   \n",
      "\n",
      "       û_  û_thank  ûªm  ûªt  ûªve   ûï  ûïharri   ûò  ûówell  \n",
      "0     0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "1     0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "2     0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "3     0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "4     0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "...   ...      ...  ...  ...   ...  ...      ...  ...     ...  \n",
      "5105  0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "5108  0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "5129  0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "5141  0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "5164  0.0      0.0  0.0  0.0   0.0  0.0      0.0  0.0     0.0  \n",
      "\n",
      "[5521 rows x 7274 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# fit the vectorizer on all words\n",
    "vectorizer.fit(df['v2'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# transform (count of each word in the vocabulary for each document.)\n",
    "bag_of_words = vectorizer.transform(df['v2'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# create a new DataFrame with the bag of words representation\n",
    "bow_df=pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# concatenate the original DataFrame and the bag of words DataFrame\n",
    "result_df = pd.concat([df, bow_df], axis=1)\n",
    "\n",
    "# print the result DataFrame\n",
    "print(result_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "KlxWELhG_4k0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlxWELhG_4k0",
    "outputId": "b174d0ae-5a8f-4d0e-aa58-0ac9af4150d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words contains non-zero elements\n"
     ]
    }
   ],
   "source": [
    "if any(bag_of_words.toarray()[0]):\n",
    "    print('Bag of words contains non-zero elements')\n",
    "else:\n",
    "    print('Bag of words is all zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea2bc406",
   "metadata": {
    "id": "ea2bc406"
   },
   "outputs": [],
   "source": [
    "#split dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "y=df['v1']\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(bow_df, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71903425",
   "metadata": {
    "id": "71903425"
   },
   "outputs": [],
   "source": [
    "# SVM Algo\n",
    "from sklearn import svm\n",
    "svcclassifier = svm.SVC(kernel='linear')\n",
    "svcclassifier.fit(xtrain, ytrain)\n",
    "y_pred = svcclassifier.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17f09207",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17f09207",
    "outputId": "15efa26f-368d-4543-9942-40901233035d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1119    2]\n",
      " [  20  152]]\n",
      "0.982985305491106\n",
      "0.987012987012987\n",
      "0.8837209302325582\n",
      "0.9325153374233128\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation for SVM\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print( accuracy_score(ytest, y_pred))\n",
    "print(precision_score(ytest, y_pred,pos_label=\"spam\"))\n",
    "print(recall_score(ytest, y_pred,pos_label=\"spam\"))\n",
    "print(f1_score(ytest, y_pred,pos_label=\"spam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48e618e9",
   "metadata": {
    "id": "48e618e9"
   },
   "outputs": [],
   "source": [
    "#desision tree algo\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtmodel = DecisionTreeClassifier(criterion=\"entropy\", random_state=50)\n",
    "dtmodel.fit(xtrain.values, ytrain.values)\n",
    "dt_pred = dtmodel.predict(xtest.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33f7668f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33f7668f",
    "outputId": "8844a79d-8545-421a-a247-0b2ab22f47b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1102   19]\n",
      " [  26  146]]\n",
      "0.9651972157772621\n",
      "0.9769503546099291\n",
      "0.9830508474576272\n",
      "0.9799911071587373\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation for desision tree alg\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print(confusion_matrix(ytest, dt_pred))\n",
    "print(accuracy_score(ytest, dt_pred))\n",
    "print(precision_score(ytest, dt_pred,pos_label=\"ham\"))\n",
    "print(recall_score(ytest, dt_pred,pos_label=\"ham\"))\n",
    "print(f1_score(ytest, dt_pred,pos_label=\"ham\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6sZvhiBfpdBB",
   "metadata": {
    "id": "6sZvhiBfpdBB"
   },
   "outputs": [],
   "source": [
    "#NaiveBayesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NaiveBayes=MultinomialNB()\n",
    "NaiveBayes.fit(xtrain.values, ytrain.values)\n",
    "NB_pred = NaiveBayes.predict(xtest.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "z7ttTVrysF6_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7ttTVrysF6_",
    "outputId": "417893a0-72f1-416d-a2c3-2bea10aad16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1110   11]\n",
      " [  11  161]]\n",
      "0.982985305491106\n",
      "0.9901873327386262\n",
      "0.9901873327386262\n",
      "0.9901873327386262\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation for Naive Bayes alg\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print(confusion_matrix(ytest, NB_pred))\n",
    "print( accuracy_score(ytest, NB_pred))\n",
    "print(precision_score(ytest, NB_pred,pos_label=\"ham\"))\n",
    "print(recall_score(ytest, NB_pred,pos_label=\"ham\"))\n",
    "print(f1_score(ytest, NB_pred,pos_label=\"ham\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
